{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff38a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shonk\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700dbafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5157142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.61      0.54       334\n",
      "           1       0.55      0.43      0.48       366\n",
      "\n",
      "    accuracy                           0.52       700\n",
      "   macro avg       0.52      0.52      0.51       700\n",
      "weighted avg       0.52      0.52      0.51       700\n",
      "\n",
      "      Sentiment_News1  Sentiment_News2  Sentiment_News3  Sentiment_News4  \\\n",
      "0                   1                0                1                1   \n",
      "1                   1                0                0                0   \n",
      "2                   1                1                1                1   \n",
      "3                   1                0                1                0   \n",
      "4                   1                0                1                0   \n",
      "...               ...              ...              ...              ...   \n",
      "3495                1               -1               -1               -1   \n",
      "3496               -1               -1               -1               -1   \n",
      "3497                0                1                1                1   \n",
      "3498                0                1                1                0   \n",
      "3499                0                0                0                1   \n",
      "\n",
      "      Sentiment_News5  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   0  \n",
      "4                   0  \n",
      "...               ...  \n",
      "3495               -1  \n",
      "3496               -1  \n",
      "3497               -1  \n",
      "3498                1  \n",
      "3499                0  \n",
      "\n",
      "[3500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"complete_data.csv\")  # Ensure the file is in the correct path\n",
    "\n",
    "# Step 2: Combine text from all news columns for model training\n",
    "df['combined_news'] = df[['News1', 'News2', 'News3', 'News4', 'News5']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "# Step 3: Create a dummy sentiment column for testing (replace this with real sentiment data if available)\n",
    "df['sentiment'] = np.random.choice([0, 1], size=len(df))  # Randomly assign 0 (negative) or 1 (positive) as sentiment\n",
    "\n",
    "# Step 4: Convert text data to feature vectors\n",
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "X = vectorizer.fit_transform(df[\"combined_news\"])\n",
    "\n",
    "# Step 5: Use the 'sentiment' column as the target variable\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 7: Train a Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# Step 9: Prediction Function\n",
    "def predict_sentiment(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return -1  # Return a special value for NaN (e.g., -1)\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    prediction = model.predict(text_vector)\n",
    "    return prediction[0]\n",
    "\n",
    "# Step 10: Create a new DataFrame with sentiment labels for each news column\n",
    "sentiment_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 6):  # Assuming there are 5 news columns\n",
    "    news_col = f\"News{i}\"  # Adjusted to 'NewsX' for consistency\n",
    "    sentiment_col = f\"Sentiment_News{i}\"  # New column to store sentiment for each news\n",
    "    sentiment_df[sentiment_col] = df[news_col].apply(lambda x: predict_sentiment(x))\n",
    "\n",
    "# Display the new DataFrame with sentiment labels for each news column\n",
    "print(sentiment_df)\n",
    "\n",
    "# Optional: Combine with the original DataFrame if needed\n",
    "final_df = pd.concat([df, sentiment_df], axis=1)\n",
    "final_df.to_csv('final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc5db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
